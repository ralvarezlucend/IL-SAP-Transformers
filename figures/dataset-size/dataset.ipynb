{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2edebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/notebooks/utils.py:290: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  \"kl_div_prefix_1_teacher_val\": \"$A_0\\,x_{t-4}$\",\n",
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/notebooks/utils.py:291: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  \"kl_div_prefix_2_teacher_val\": \"$A_0\\,x_{t-4} + A_1\\,x_{t-3}$\",\n",
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/notebooks/utils.py:292: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  \"kl_div_prefix_3_teacher_val\": \"$A_0\\,x_{t-4} + A_1\\,x_{t-3} + A_2\\,x_{t-2}$\",\n",
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from notebooks.utils import fetch_runs, get_runs_data, differing_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d683b017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youthful-fog-1711\n",
      "glowing-armadillo-1712\n",
      "faithful-oath-1717\n",
      "bumbling-brook-1718\n",
      "devout-thunder-1721\n",
      "upbeat-glade-1723\n",
      "solar-sun-1725\n",
      "celestial-sky-1728\n",
      "noble-dragon-1729\n",
      "fresh-forest-1730\n"
     ]
    }
   ],
   "source": [
    "runs = fetch_runs(\n",
    "    entity=\"r-alvarezlucendo16\", project=\"incremental-learning\", tags_any=[\"ICLR-minimal-dataset\"]\n",
    ")\n",
    "df = get_runs_data(runs, metrics=[\n",
    "    \"val_loss\", \n",
    "    \"teacher_val_loss\",\n",
    "    \"val_best\",\n",
    "    \"kl_div_unigram_learned_val\", \n",
    "    \"kl_div_bigram_learned_val\", \n",
    "    \"kl_div_trigram_learned_val\"\n",
    "])\n",
    "for run in runs:\n",
    "    print(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3b5769",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cfg.dataset.number.train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m groups = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_run_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcfg.dataset.number.train\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mteacher_val_loss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mval_best\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      4\u001b[39m groups = \u001b[38;5;28msorted\u001b[39m(groups, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: (x[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m] < \u001b[32m0\u001b[39m, x[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m]))\n\u001b[32m      5\u001b[39m max_step = \u001b[32m1000\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pandas/core/frame.py:9210\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9208\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9213\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9216\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9220\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1331\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1328\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1342\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'cfg.dataset.number.train'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[[\"val_loss\", \"teacher_val_loss\", \"val_best\"]]\n",
    "groups = sorted(groups, key=lambda x: (x[0][1] < 0, x[0][1]))\n",
    "max_step = 1000\n",
    "for (run_id, num_train), data in groups:\n",
    "    loss = data[\"val_loss\"].tolist()\n",
    "    if num_train == 600 or num_train == 2000 or num_train == 9000 or num_train == -3000:\n",
    "        val_loss = data[\"val_best\"].tolist()\n",
    "        teacher_val_loss = data[\"teacher_val_loss\"].unique()[0]\n",
    "        val_loss = val_loss - teacher_val_loss\n",
    "        val_loss = val_loss[:max_step]\n",
    "        if num_train < 0:\n",
    "            label = \"online\"\n",
    "            linestyle = \"--\"\n",
    "            color = \"black\"\n",
    "        else:\n",
    "            label = str(num_train)\n",
    "            linestyle = \"-\"\n",
    "            color = None\n",
    "        plt.plot(val_loss, label=label, linewidth=2, linestyle=linestyle, color=color)\n",
    "\n",
    "# Get handles/labels from the current axes\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "# Figure-level legend above the plot\n",
    "plt.gcf().legend(\n",
    "    handles, labels,\n",
    "    loc=\"upper center\",\n",
    "    ncol=len(labels),\n",
    "    fontsize=14,\n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(0.52, 1.04)\n",
    ")\n",
    "\n",
    "# Make room for the top legend\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.xlabel(\"Step\", fontsize=20)\n",
    "plt.ylabel(\"Excess Best Loss\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()\n",
    "# plt.savefig(\"val-loss-dataset-exps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[[\"kl_div_unigram_learned_val\", \"kl_div_bigram_learned_val\", \"kl_div_trigram_learned_val\"]]\n",
    "groups = sorted(groups, key=lambda x: x[0][1])\n",
    "max_step = 1000\n",
    "\n",
    "for (run_id, num_train), data in groups:\n",
    "    kl_div_unigram_learned_val = data[\"kl_div_unigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_div_bigram_learned_val = data[\"kl_div_bigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_div_teacher_val = data[\"kl_div_trigram_learned_val\"].tolist()[:max_step]\n",
    "    if num_train == 400 or num_train == 2000 or num_train == 9000:\n",
    "        plt.plot(kl_div_unigram_learned_val, linewidth=2)\n",
    "        plt.plot(kl_div_bigram_learned_val, linewidth=2)\n",
    "        plt.plot(kl_div_teacher_val, linewidth=2)\n",
    "        plt.xlabel(\"Step\", fontsize=16)\n",
    "        plt.ylabel(\"KL Divergence\", fontsize=16)\n",
    "        plt.legend(loc=\"upper right\", fontsize=16,  framealpha=1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdadbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "selected_nums = [400, 2000, 9000]\n",
    "max_step = 1000\n",
    "\n",
    "picked = {}\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in selected_nums and num_train not in picked:\n",
    "        picked[num_train] = (run_id, data)\n",
    "    if len(picked) == len(selected_nums):\n",
    "        break\n",
    "\n",
    "ncols = len(selected_nums)\n",
    "fig, axes = plt.subplots(1, ncols, figsize=(4*ncols, 4), sharey=True)\n",
    "if ncols == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "handles, labels = None, None\n",
    "for ax, num_train in zip(axes, selected_nums):\n",
    "    run = picked.get(num_train)\n",
    "    if run is None:\n",
    "        ax.set_visible(False)\n",
    "        continue\n",
    "\n",
    "    run_id, data = run\n",
    "    kl_uni = data[\"kl_div_unigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_bi  = data[\"kl_div_bigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_t   = data[\"kl_div_trigram_learned_val\"].tolist()[:max_step]\n",
    "\n",
    "    ln1, = ax.plot(kl_uni, linewidth=2)\n",
    "    ln2, = ax.plot(kl_bi,  linewidth=2)\n",
    "    ln3, = ax.plot(kl_t,   linewidth=2)\n",
    "\n",
    "    if handles is None:\n",
    "        handles, labels = [ln1, ln2, ln3], [\"4-gram\", \"8-gram\", \"12-gram\"]\n",
    "\n",
    "    ax.set_title(f\"$\\\\mathbf{{{num_train}}}\\\\text{{ samples}}$\", fontsize=20)\n",
    "    ax.set_xlabel(\"Step\", fontsize=20)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "axes[0].set_ylabel(\"KL Divergence\", fontsize=20)\n",
    "axes[0].yaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "fig.legend(\n",
    "    handles, \n",
    "    labels, \n",
    "    loc=\"upper center\", \n",
    "    ncol=3, \n",
    "    fontsize=18, \n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(0.5, 1.11)\n",
    ")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "# plt.savefig(\"figures/dataset-size/results/kl-divergence-dataset-exps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c1ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cycler\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import numpy as np\n",
    "\n",
    "# ---- Prepare grouped data once ----\n",
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[\n",
    "    [\"val_loss\", \"teacher_val_loss\", \"val_best\",\n",
    "     \"kl_div_unigram_learned_val\", \"kl_div_bigram_learned_val\", \"kl_div_trigram_learned_val\"]\n",
    "]\n",
    "groups = sorted(groups, key=lambda x: (x[0][1] < 0, x[0][1]))\n",
    "\n",
    "# ---- What to show where ----\n",
    "kl_selected_nums = [600, 2000, 9000]      # columns 2â€“4 (KL)\n",
    "val_selected = [600, 2000, 9000, -3000]   # column 1 (val-loss incl. online=-3000)\n",
    "max_step = 1000\n",
    "\n",
    "# ---- Pick one run per selected num_train for the KL panels ----\n",
    "picked = {}\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in kl_selected_nums and num_train not in picked:\n",
    "        picked[num_train] = (run_id, data)\n",
    "    if len(picked) == len(kl_selected_nums):\n",
    "        break\n",
    "\n",
    "# ---- Figure & axes ----\n",
    "# Use a bit wider figure so we can squeeze KL axes together without cramping labels\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6), sharey=False)\n",
    "ax_val = axes[0]\n",
    "ax_kl_list = axes[1:]\n",
    "\n",
    "val_colors = [\"tab:red\", \"tab:purple\", \"tab:brown\"]  # for 600, 2000, 9000\n",
    "ax_val.set_prop_cycle(cycler(color=val_colors))\n",
    "\n",
    "# Colors for KL curves (fixed, distinct from val colors)\n",
    "kl_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]   # uni, bi, tri (4/8/12-gram)\n",
    "\n",
    "# ---- Val-loss panel (first axis) ----\n",
    "val_handles = []\n",
    "val_labels = []\n",
    "seen_label = set()\n",
    "\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in val_selected:\n",
    "        val_loss = data[\"val_best\"].tolist()\n",
    "        teacher_val_loss = data[\"teacher_val_loss\"].unique()[0]\n",
    "        y = (val_loss - teacher_val_loss)[:max_step]\n",
    "\n",
    "        if num_train < 0:\n",
    "            label = \"online\"\n",
    "            linestyle = \"--\"\n",
    "            color = \"black\"   # stays black, outside the cycler\n",
    "        else:\n",
    "            label = str(num_train)\n",
    "            linestyle = \"-\"\n",
    "            color = None      # uses ax_val's distinct color cycle\n",
    "\n",
    "        ln, = ax_val.plot(y, label=label, linewidth=2, linestyle=linestyle, color=color)\n",
    "        if label not in seen_label:\n",
    "            val_handles.append(ln)\n",
    "            val_labels.append(label)\n",
    "            seen_label.add(label)\n",
    "\n",
    "ax_val.set_xlabel(\"Step\", fontsize=24)\n",
    "ax_val.set_ylabel(\"Best Excess Loss\", fontsize=24)\n",
    "ax_val.tick_params(labelsize=20)\n",
    "\n",
    "# ---- KL panels (next three axes) ----\n",
    "kl_handles, kl_labels = None, None\n",
    "for ax, num_train in zip(ax_kl_list, kl_selected_nums):\n",
    "    run = picked.get(num_train)\n",
    "    if run is None:\n",
    "        ax.set_visible(False)\n",
    "        continue\n",
    "\n",
    "    _, data = run\n",
    "    kl_uni = data[\"kl_div_unigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_bi  = data[\"kl_div_bigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_tri = data[\"kl_div_trigram_learned_val\"].tolist()[:max_step]\n",
    "\n",
    "    ln1, = ax.plot(kl_uni, linewidth=2, color=kl_colors[0])\n",
    "    ln2, = ax.plot(kl_bi,  linewidth=2, color=kl_colors[1])\n",
    "    ln3, = ax.plot(kl_tri, linewidth=2, color=kl_colors[2])\n",
    "\n",
    "    # mark the step of best validation loss\n",
    "    raw_val = data[\"val_best\"].tolist()[:max_step]\n",
    "    if len(raw_val) > 0:\n",
    "        best_step = int(np.nanargmin(raw_val))\n",
    "        ax.axvline(best_step, linestyle=\":\", linewidth=2, color=\"grey\", alpha=0.9)\n",
    "\n",
    "    if kl_handles is None:\n",
    "        kl_handles, kl_labels = [ln1, ln2, ln3], [\"4-gram\", \"8-gram\", \"12-gram\"]\n",
    "\n",
    "    ax.set_title(f\"$\\\\mathbf{{{num_train}}}\\\\,\\\\text{{samples}}$\", fontsize=28)\n",
    "    ax.set_xlabel(\"Step\", fontsize=24)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1.0))\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "ax_kl_list[0].set_ylabel(\"KL Divergence\", fontsize=24)\n",
    "\n",
    "# ---- Layout first so axes positions are final-ish ----\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "gap = 0.02  # small gap between KL panels\n",
    "# Use current width of first KL axis for all\n",
    "first_pos = ax_kl_list[0].get_position()\n",
    "kl_w = first_pos.width\n",
    "# Keep the left x0 of the first KL axis; pack the next two right next to it\n",
    "x0 = first_pos.x0\n",
    "y0 = first_pos.y0\n",
    "h  = first_pos.height\n",
    "\n",
    "for i, ax in enumerate(ax_kl_list):\n",
    "    ax.set_position([x0 + i * (kl_w + gap), y0, kl_w, h])\n",
    "\n",
    "# ---- Recompute positions for legend anchors after manual positioning ----\n",
    "val_pos = ax_val.get_position()\n",
    "val_center_x = val_pos.x0 + val_pos.width / 2\n",
    "val_top_y = val_pos.y1\n",
    "\n",
    "kl_left = min(ax.get_position().x0 for ax in ax_kl_list)\n",
    "kl_right = max(ax.get_position().x1 for ax in ax_kl_list)\n",
    "kl_top_y = max(ax.get_position().y1 for ax in ax_kl_list)\n",
    "kl_center_x = (kl_left + kl_right) / 2\n",
    "\n",
    "# ---- Legends above their sections ----\n",
    "fig.legend(\n",
    "    val_handles, val_labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol=4,\n",
    "    fontsize=22,\n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(val_center_x, val_top_y + 0.07),\n",
    "    bbox_transform=fig.transFigure,\n",
    "    columnspacing=0.65, \n",
    ")\n",
    "\n",
    "fig.legend(\n",
    "    kl_handles, kl_labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol=len(kl_labels),\n",
    "    fontsize=22,\n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(kl_center_x, kl_top_y + 0.09),\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/dataset-size/results/dataset-experiments.pdf\", bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ar-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
