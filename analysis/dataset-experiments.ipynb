{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/rodrigoalvarezlucendo/Desktop/ar-classification/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from analysis.utils import fetch_runs, get_runs_data, differing_config\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cycler\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dictionary update sequence element #0 has length 1; 2 is required",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m runs = fetch_runs(tags_any=[\u001b[33m\"\u001b[39m\u001b[33mICLR-minimal-dataset\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mget_runs_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mteacher_val_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval_best\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkl_div_unigram_learned_val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkl_div_bigram_learned_val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkl_div_trigram_learned_val\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m runs:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(run.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ar-classification/analysis/utils.py:74\u001b[39m, in \u001b[36mget_runs_data\u001b[39m\u001b[34m(runs, metrics, step_key, include_config, config_sep, config_prefix)\u001b[39m\n\u001b[32m     71\u001b[39m meta = {\u001b[33m\"\u001b[39m\u001b[33m_run_id\u001b[39m\u001b[33m\"\u001b[39m: r.id, \u001b[33m\"\u001b[39m\u001b[33m_run_name\u001b[39m\u001b[33m\"\u001b[39m: r.name}\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_config:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     flat_cfg = pd.json_normalize(\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m, sep=config_sep)\n\u001b[32m     75\u001b[39m     flat_cfg = flat_cfg.add_prefix(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconfig_sep\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     76\u001b[39m     meta.update(flat_cfg.to_dict(orient=\u001b[33m\"\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: dictionary update sequence element #0 has length 1; 2 is required"
     ]
    }
   ],
   "source": [
    "runs = fetch_runs(tags_any=[\"ICLR-minimal-dataset\"])\n",
    "df = get_runs_data(\n",
    "    runs,\n",
    "    metrics=[\n",
    "        \"val_loss\",\n",
    "        \"teacher_val_loss\",\n",
    "        \"val_best\",\n",
    "        \"kl_div_unigram_learned_val\",\n",
    "        \"kl_div_bigram_learned_val\",\n",
    "        \"kl_div_trigram_learned_val\",\n",
    "    ],\n",
    ")\n",
    "for run in runs:\n",
    "    print(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"cfg.teacher.span_lengths\"])\n",
    "differing_config(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Loss by Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[\n",
    "    [\"val_loss\", \"teacher_val_loss\", \"val_best\"]\n",
    "]\n",
    "groups = sorted(groups, key=lambda x: (x[0][1] < 0, x[0][1]))\n",
    "max_step = 1000\n",
    "\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in [600, 2000, 9000, -3000]:\n",
    "        val_loss = data[\"val_best\"].tolist()\n",
    "        teacher_val_loss = data[\"teacher_val_loss\"].unique()[0]\n",
    "        val_loss = val_loss - teacher_val_loss\n",
    "        val_loss = val_loss[:max_step]\n",
    "        label = \"online\" if num_train < 0 else str(num_train)\n",
    "        linestyle = \"--\" if num_train < 0 else \"-\"\n",
    "        color = \"black\" if num_train < 0 else None\n",
    "        plt.plot(val_loss, label=label, linewidth=2, linestyle=linestyle, color=color)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.gcf().legend(\n",
    "    handles, labels, loc=\"upper center\", ncol=len(labels), fontsize=14, framealpha=1, bbox_to_anchor=(0.52, 1.04)\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.xlabel(\"Step\", fontsize=20)\n",
    "plt.ylabel(\"Excess Best Loss\", fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.savefig(\"figures/val-loss-dataset-exps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Divergence by Dataset Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[\n",
    "    [\"kl_div_unigram_learned_val\", \"kl_div_bigram_learned_val\", \"kl_div_trigram_learned_val\"]\n",
    "]\n",
    "groups = sorted(groups, key=lambda x: x[0][1])\n",
    "\n",
    "selected_nums = [600, 2000, 9000]\n",
    "max_step = 1000\n",
    "\n",
    "picked = {}\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in selected_nums and num_train not in picked:\n",
    "        picked[num_train] = (run_id, data)\n",
    "    if len(picked) == len(selected_nums):\n",
    "        break\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4), sharey=True)\n",
    "handles, labels = None, None\n",
    "\n",
    "for ax, num_train in zip(axes, selected_nums):\n",
    "    run_id, data = picked[num_train]\n",
    "    kl_uni = data[\"kl_div_unigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_bi = data[\"kl_div_bigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_t = data[\"kl_div_trigram_learned_val\"].tolist()[:max_step]\n",
    "\n",
    "    ln1, = ax.plot(kl_uni, linewidth=2)\n",
    "    ln2, = ax.plot(kl_bi, linewidth=2)\n",
    "    ln3, = ax.plot(kl_t, linewidth=2)\n",
    "\n",
    "    if handles is None:\n",
    "        handles, labels = [ln1, ln2, ln3], [\"4-gram\", \"8-gram\", \"12-gram\"]\n",
    "\n",
    "    ax.set_title(f\"$\\\\mathbf{{{num_train}}}\\\\text{{ samples}}$\", fontsize=20)\n",
    "    ax.set_xlabel(\"Step\", fontsize=20)\n",
    "    ax.xaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "axes[0].set_ylabel(\"KL Divergence\", fontsize=20)\n",
    "axes[0].yaxis.set_tick_params(labelsize=16)\n",
    "\n",
    "fig.legend(handles, labels, loc=\"upper center\", ncol=3, fontsize=18, framealpha=1, bbox_to_anchor=(0.5, 1.11))\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(\"figures/kl-divergence-dataset-exps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby([\"_run_name\", \"cfg.dataset.number.train\"])[\n",
    "    [\n",
    "        \"val_loss\",\n",
    "        \"teacher_val_loss\",\n",
    "        \"val_best\",\n",
    "        \"kl_div_unigram_learned_val\",\n",
    "        \"kl_div_bigram_learned_val\",\n",
    "        \"kl_div_trigram_learned_val\",\n",
    "    ]\n",
    "]\n",
    "groups = sorted(groups, key=lambda x: (x[0][1] < 0, x[0][1]))\n",
    "\n",
    "kl_selected_nums = [600, 2000, 9000]\n",
    "val_selected = [600, 2000, 9000, -3000]\n",
    "max_step = 1000\n",
    "\n",
    "picked = {}\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in kl_selected_nums and num_train not in picked:\n",
    "        picked[num_train] = (run_id, data)\n",
    "    if len(picked) == len(kl_selected_nums):\n",
    "        break\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(24, 6), sharey=False)\n",
    "ax_val = axes[0]\n",
    "ax_kl_list = axes[1:]\n",
    "\n",
    "val_colors = [\"tab:red\", \"tab:purple\", \"tab:brown\"]\n",
    "ax_val.set_prop_cycle(cycler(color=val_colors))\n",
    "kl_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\"]\n",
    "\n",
    "# Val loss panel\n",
    "val_handles, val_labels = [], []\n",
    "seen_label = set()\n",
    "\n",
    "for (run_id, num_train), data in groups:\n",
    "    if num_train in val_selected:\n",
    "        val_loss = data[\"val_best\"].tolist()\n",
    "        teacher_val_loss = data[\"teacher_val_loss\"].unique()[0]\n",
    "        y = (val_loss - teacher_val_loss)[:max_step]\n",
    "\n",
    "        label = \"online\" if num_train < 0 else str(num_train)\n",
    "        linestyle = \"--\" if num_train < 0 else \"-\"\n",
    "        color = \"black\" if num_train < 0 else None\n",
    "\n",
    "        (ln,) = ax_val.plot(y, label=label, linewidth=2, linestyle=linestyle, color=color)\n",
    "        if label not in seen_label:\n",
    "            val_handles.append(ln)\n",
    "            val_labels.append(label)\n",
    "            seen_label.add(label)\n",
    "\n",
    "ax_val.set_xlabel(\"Step\", fontsize=24)\n",
    "ax_val.set_ylabel(\"Best Excess Loss\", fontsize=24)\n",
    "ax_val.tick_params(labelsize=20)\n",
    "\n",
    "# KL panels\n",
    "kl_handles, kl_labels = None, None\n",
    "for ax, num_train in zip(ax_kl_list, kl_selected_nums):\n",
    "    _, data = picked[num_train]\n",
    "    kl_uni = data[\"kl_div_unigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_bi = data[\"kl_div_bigram_learned_val\"].tolist()[:max_step]\n",
    "    kl_tri = data[\"kl_div_trigram_learned_val\"].tolist()[:max_step]\n",
    "\n",
    "    ln1, = ax.plot(kl_uni, linewidth=2, color=kl_colors[0])\n",
    "    ln2, = ax.plot(kl_bi, linewidth=2, color=kl_colors[1])\n",
    "    ln3, = ax.plot(kl_tri, linewidth=2, color=kl_colors[2])\n",
    "\n",
    "    raw_val = data[\"val_best\"].tolist()[:max_step]\n",
    "    if len(raw_val) > 0:\n",
    "        best_step = int(np.nanargmin(raw_val))\n",
    "        ax.axvline(best_step, linestyle=\":\", linewidth=2, color=\"grey\", alpha=0.9)\n",
    "\n",
    "    if kl_handles is None:\n",
    "        kl_handles, kl_labels = [ln1, ln2, ln3], [\"4-gram\", \"8-gram\", \"12-gram\"]\n",
    "\n",
    "    ax.set_title(f\"$\\\\mathbf{{{num_train}}}\\\\,\\\\text{{samples}}$\", fontsize=28)\n",
    "    ax.set_xlabel(\"Step\", fontsize=24)\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(1.0))\n",
    "    ax.tick_params(labelsize=20)\n",
    "\n",
    "ax_kl_list[0].set_ylabel(\"KL Divergence\", fontsize=24)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.9])\n",
    "\n",
    "gap = 0.02\n",
    "first_pos = ax_kl_list[0].get_position()\n",
    "kl_w, x0, y0, h = first_pos.width, first_pos.x0, first_pos.y0, first_pos.height\n",
    "for i, ax in enumerate(ax_kl_list):\n",
    "    ax.set_position([x0 + i * (kl_w + gap), y0, kl_w, h])\n",
    "\n",
    "val_pos = ax_val.get_position()\n",
    "val_center_x = val_pos.x0 + val_pos.width / 2\n",
    "kl_left = min(ax.get_position().x0 for ax in ax_kl_list)\n",
    "kl_right = max(ax.get_position().x1 for ax in ax_kl_list)\n",
    "kl_top_y = max(ax.get_position().y1 for ax in ax_kl_list)\n",
    "kl_center_x = (kl_left + kl_right) / 2\n",
    "\n",
    "fig.legend(\n",
    "    val_handles,\n",
    "    val_labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol=4,\n",
    "    fontsize=22,\n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(val_center_x, val_pos.y1 + 0.07),\n",
    "    bbox_transform=fig.transFigure,\n",
    "    columnspacing=0.65,\n",
    ")\n",
    "\n",
    "fig.legend(\n",
    "    kl_handles,\n",
    "    kl_labels,\n",
    "    loc=\"lower center\",\n",
    "    ncol=3,\n",
    "    fontsize=22,\n",
    "    framealpha=1,\n",
    "    bbox_to_anchor=(kl_center_x, kl_top_y + 0.09),\n",
    "    bbox_transform=fig.transFigure,\n",
    ")\n",
    "\n",
    "plt.savefig(\"figures/dataset-experiments.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ar-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
